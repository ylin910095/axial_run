l6496f211b630m0012m0363m432_continue:
    loc: /global/cfs/cdirs/m3652/hisq/l6496f211b630m0012m0363m432

    max_jobs: 30 # maximum number of jobs in queue at the same time
    # Shell command that returns the number of queued jobs
    check_jobs_command: "squeue -u ylin|wc -l"

    # The shell command for checking the number of jobs in queue
    cluster_param: 
            # Note that "#SBATCH --output=blah" will be automatically
            # added during the run time and saved to ${datadir}/slurmout
            # directory
            slurm_header:
                - "#SBATCH --account=axialgpu-21-22"
                - "#SBATCH --nodes=1"
                - "#SBATCH --ntasks-per-node=4"
                - "#SBATCH --gres=gpu:4"
                - "#SBATCH --time=1:00:00"
                - "#SBATCH --partition=long"
                - "#SBATCH --job-name=omega"
                - "#SBATCH --mail-user=99liny@gmail.com"
                - "#SBATCH --mail-type=FAIL,TIME_LIMIT"
            module_command: 
                - module purge
                - module load anaconda2 gcc/8.3.0 cuda/10.1 openmpi/3.1.5-gcc-8.3.0-cuda10.1
                - export LD_LIBRARY_PATH=/sdcc/u/ylin/lqcd/yin/software/quda/build/lib:$LD_LIBRARY_PATH
            no_config: 1 # number of configurations running in parallel per job for bundling purpose
            mpi_rank_per_node: 4 # make sure it matches slurm_header --nodes
            openmp_thread_per_rank: 8 # make sure it matches slurm header --ntasks-per-node
            QUDA_RESOURCE_PATH: /sdcc/u/ylin/QUDA/tuning-files-K80-omega  # tunning file folder for QUDA. Ignored if not using GPUs.                                                                                 

            projdir: /sdcc/u/ylin/axial/input_dir/omega_gpu/axial_run # the directory of the scripts

            # Data saving directory: 
            # $datadir/corr for correlator, $datadir/prop for propagators, and so on
            # if not directory not present, it will be created
            datadir: /sdcc/u/ylin/axial/input_dir/omega_gpu/axial_run/datadir/l3248f211b580m002426m06730m8447_test # data saving directory
            rundb: omega_test.sqlite # the name of this file, searched under projdir/run_db
            milcbin: ks_spectrum_hisq_gb_baryon_blind_no_sink_links # searched under projdir/bin

            # Scratch directory for intermediate correlator files
            # The script will create a unique scrach folder for each job within this folder
            scratchdir: /hpcgpfs01/work/lqcd/axial/yin/temp

    # All pmt tasks, this correponds to the parameters required for pythonprompt
    # defined in the cluster param
    pmt_file: /sdcc/u/ylin/axial/input_dir/omega_gpu/axial_run/pmt/pmt_2pt_strange_no_multisrc.py
    pmt_param: 
        a015_phy_mass0_t0_g1:
            t0: 0
            mass: 0.06730
            gauss_smearing:
                r0: 1.0
                N: 30
            inversion:
                L2: 1e-12
                R2: 0
                restarts: 50
                iters: 1000
            nconfigs: 100
        a015_phy_mass0_t0_g2:
            t0: 0
            mass: 0.06730
            gauss_smearing:
                r0: 2.0 
                N: 30
            inversion:
                L2: 1e-12
                R2: 0
                restarts: 50
                iters: 1000
            nconfigs: 100 
        a015_phy_mass0_t0_g3:
            t0: 0
            mass: 0.06730
            gauss_smearing:
                r0: 3.0 
                N: 30
            inversion:
                L2: 1e-12
                R2: 0
                restarts: 50
                iters: 1000
            nconfigs: 100 
        a015_phy_mass0_t0_g4:
            t0: 0
            mass: 0.06730
            gauss_smearing:
                r0: 4.0 
                N: 30
            inversion:
                L2: 1e-12
                R2: 0
                restarts: 50
                iters: 1000
            nconfigs: 100 
